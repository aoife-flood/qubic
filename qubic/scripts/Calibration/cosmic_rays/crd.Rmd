---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.5
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Cosmic-Rays analysis above noise

The analysis is divided into two parts:
* **Single TES Analysis**: This jupyter-notebook
* **Analysis of all TES**: .py script

The main difference is in the distribution of work: single core (jupyter) vs multiprocessing (.py script)

Note: the functions present in jupyter are intentionally redundant in order to be more versatile for tests and modifications

```{python pycharm={'is_executing': True}}
import os
import sys
import time as tm
import numpy as np
import subprocess as sp
import matplotlib.pyplot as plt
from scipy.interpolate import CubicSpline

# %matplotlib inline
```

## Data preparation

The algorithm is optimized to work with arrays of type numpy.
Raw data is in .fits.
The algorithm runs a script (wrapper_qubic.py) which exports them into numpy-readable files (.npy and .npz).

**Why export data in numpy compatible format?**
For reasons of efficiency this notebook and the .py script were developed and tested on python3.11 (also runs on python3.10).

Since the qubic libraries are not compatible with python versions >= 3.10, it was necessary
use two environments:

* > **A** (with python version < 3.10), where the qubic package and all dependencies are installed;
* > **B** (with python version 3.10 or higher), on which the .py notebook/script is run and tested;

wrapper_qubic.py creates a "bridge" between the environment in which the cosmic ray search code runs
and the environment that contains the qubic package.

wrapper_qubic.py will be run with environment interpreter A:
* read .fits data via "read_qubicstudio_dataset" method;
* save data in numpy-readable formats (.npy and .npz);

wrapper_qubic.py takes as command line arguments:
* the path of the folder containing the .fits files;
* the path of the file in which to save the time data (.npy format);
* the path of the file in which to save the signal data (.npz format);

If A coincides with B:
* qubic_interpreter must be assigned sys.executable (qubic_interpreter = sys.executable);

```{python}
data_storage_path = "/home/user/QUBIC/storage" 
qubic_interpreter = sys.executable 
data_set_path = "/home/user/QUBIC/data/2022-07-14/2022-07-14_23.54.19__MoonScan_Speed_VE14"
```

```{python pycharm={'is_executing': True}}
def configure_data_dir(data_storage_path: str, data_set_path: str, qubic_interpreter: str = sys.executable) -> tuple: 
    """
    configuration of the interpreter for data export and the saving point of the exported files 
    (.npy and .npz format)
    
        :param data_storage_path: str
            folder where two subfolders are created:
                1. input, which contains the .npy (time) and .npz (signals of all TES) files;
                2. output, which contains the .txt file of the filtered tau;
        
        :param data_set_path: str
            folder containing sky scan data in .fits format
            
        :param qubic_interpreter: str
            interpreter for data export
    
    :return: Tuple[str] 
        path to the file where the time, signals and filtered taus are saved
    
    """
    
    observation_dir = os.path.join(data_storage_path, data_set_path.split(os.sep)[-1])
    os.makedirs(observation_dir, exist_ok=True)
    
    time_fname = os.path.join(observation_dir, "times_raw.npy")
    signals_fname = os.path.join(observation_dir, "signals_raw.npz")
    output_dir = os.path.join(data_storage_path, "output")
    os.makedirs(output_dir, exist_ok=True) 
    
    taus_fname = os.path.join(output_dir, "filtered_taus_{}.txt")
    
    # sp.run returns an exception if the wrapper_qubic.py script failed to export the data
    args = [data_set_path, time_fname, signals_fname]
    _ = sp.run([qubic_interpreter, "wrapper_qubic.py"] + args, stdout=sp.DEVNULL, check=True)
    
    
    return time_fname, signals_fname, taus_fname
    


def interpolated_signal(tes_num: int, time_fname: str, signals_fname: str):
    """
    Interpolation of the signal with a third degree function (atmosphere drift removal)
        
        :param n_tes: int
            TES number
        
        :param time_fname: str
            path to the file where the time values are saved
            
        :param signals_fname: srt
            path to the file where the signal values are saved

    :return: tuple
        TEST number, CubicSpline object: coefficients of the polynomial, breakpoints 
    """
    
    time = np.load(time_fname)
    time -= time[0]
    
    signal = np.load(signals_fname)[str(tes_num)]
    
    # bc_type: boundary condition -> natural: second derivatives at the extremes of the curve are zero
    return tes_num, CubicSpline(time, signal, bc_type="natural")

def straight_line(p1: list, p2: list):
    """
    Straight line passing through two points

        :param p1: list
            x,y of the point
        
        :param p2: list
            x,y of the point

    :return: lambda function
        straight line equation
    """
    
    x, y = 0, 1

    m = (p1[y] - p2[y]) / (p1[x] - p2[x])
    q = (p1[x] * p2[y] - p2[x] * p1[y]) / (p1[x] - p2[x])

    return lambda t: m * t + q


def get_candidates(tes_num: int, 
                       time_fname: str,
                       signal_clean: CubicSpline,
                       std_coeff: int = 5,
                       points_per_candidate: int = 7) -> list:
    
    """
    Search for consecutive points in the signal that follow a decreasing trend
    
        :param n_tes: int
            TES number

        :param time_fname: str
            path to the file where the time values are saved
        
        :param signal_clean: CubicSpline
            object that generates the signal cleaned from the atmosphere
        
        :param std_coeff: int
            threshold above which I look for the starting point of a possible cosmic ray
        
        :param: points_per_candidate: int
            minimum number of points to consider it as a candidate

    :return: list
        list of lists, where each row is a candidate
    """
    
    time = np.load(time_fname)
    time -= time[0]
    
    
    j = 0
    candidates = []
    s_clean_fabs = np.fabs(signal_clean(time, 1))
    index_up_sigma = np.where(s_clean_fabs > std_coeff * np.std(s_clean_fabs))[0]

    for i in index_up_sigma:  # for each point above index_up_sigma

        if i < j: # I skip the index_up_sigma points that are already present in a candidate
            continue
        points = []

        for j in range(i, s_clean_fabs.shape[0] - 1): # iterate over the points above and below the threshold starting from 
                                                      # the index point "i"
            if s_clean_fabs[j] < s_clean_fabs[j + 1]: # I add indices to the candidate until the condition is verified:
                                                      # i.e. when the value of the signal at index "j" is less than 
                                                      # the value of the signal at index "j+1"
                points.append(j)  # I add the last value that satisfies the condition
                if len(points) > points_per_candidate: # once the indexes have been acquired for a candidate, 
                                                 # I add it to the list of candidates only if it has at least 
                                                 # "points_per_candidate" points
                    candidates.append(points)
                break
            points.append(j)  # when I don't enter the first "if", I add the consecutive decreasing points to "points"

    return candidates


def candidate_filter(time_fname: str,
                     s_clean_fabs: np.ndarray,
                     candidate: list,
                     points_vertical_trend: int = 7) -> bool:
    
    """
    Returns True or False depending on whether the candidate is valid or not

        :param time_fname: str
            path to the file where the time values are saved
        
        :param candidate: list 
            a candidate
            
        :param signal_clean: CubicSpline
            object that generates the signal cleaned from the atmosphere
              
        :param points_vertical_trend: int
            number of points preceding the candidate whose increasing linear trend is to be verified

    :return: bool
        True if the candidate is valid
        False if the candidate is not valid
    """
    
    time = np.load(time_fname)
    time -= time[0]
    
    log_Data = np.log(s_clean_fabs[candidate])
    
    # if the logarithm of the signal takes on the value infinite or nan, the candidate under examination is NOT valid
    if np.isinf(log_Data).any() or np.isnan(log_Data).any(): 
        return False 

    stop = len(candidate) // 2
    
    # I establish if a candidate is valid by generating lines connecting 
    #Â point p1 (at index "index") of the candidate under examination with point p2 (at index "-index - 1")
    for index in range(stop): 
        p1 = [time[candidate][index], s_clean_fabs[candidate][index]]
        p2 = [time[candidate][-index - 1], s_clean_fabs[candidate][-index - 1]]
    
        straight = straight_line(p1, p2)
        
        x1, y1 = time[candidate][index + 1], s_clean_fabs[candidate][index + 1]
        x2, y2 = time[candidate][- index - 2], s_clean_fabs[candidate][- index - 2]

        
    # For each point (p1) I take its mirror point (p2), connect them with a straight line 
    # and check that the point after p1 and the point before p2 are below the straight line
        if straight(x1) - y1 < 0 or straight(x2) - y2 < 0:
            return False 
    
    # Given the candidate's first index, I consider the previous 
    # "points_vertical_trend" indexes to verify that the signal follows a vertical growth
    
    # First starting point for verifying vertical growth. 
    # It respects the edge conditions of the signal array
    first_vertical_point = max(0, candidate[0] - points_vertical_trend)
    
        
    # check that the "points_vertical_trend" points preceding the candidate are strictly increasing
    for index in range(first_vertical_point, candidate[0] - 1):
        
        if s_clean_fabs[index] > s_clean_fabs[index + 1]:
            return False    
    
    # the points follow a vertical trend if the straight line connecting the first and last point 
    # has an angular coefficient greater than 1 (theta greater than 45 degrees)
    
    delta_x = time[candidate[0]] - time[first_vertical_point] 
    delta_y = s_clean_fabs[candidate[0]] - s_clean_fabs[first_vertical_point]
    
    if np.pi/4 * delta_x > delta_y:
        return False
    
            
    return True


def candidates_filter(time_fname: str, signal_clean: CubicSpline, candidates: list) -> list:
    
    """
    The function returns the list of valid candidates

        :param time_fname: str
            path to the file where the time values are saved
            
        :param signal_clean: CubicSpline
            object that generates the signal cleaned from the atmosphere
        
        :param candidates: list 
            list of candidates

    :return: list
        valid candidates
        
    """
    
    time = np.load(time_fname)
    time -= time[0]
    
    s_clean_fabs = np.fabs(signal_clean(time, 1))

    return list(filter(lambda candidate: candidate_filter(time_fname, s_clean_fabs, candidate), candidates))


def get_fit_candidates(time_fname: str, signal_clean: CubicSpline, candidates: list):
    
    """
     The function performs the fit of valid candidates

         :param time_fname: str
             path to the file where the time values are saved

         :param signal_clean: CubicSpline
             object that generates the signal cleaned from the atmosphere

         :param candidates: list 
             list of candidates
     
    :return: np.ndarray
        matrix of coefficients m (angular coeff), q (intercept) of valid candidates
    """
    
    time = np.load(time_fname)
    time -= time[0]
 
    std = np.std(np.fabs(signal_clean(time, 1)))
    
    fit = np.zeros((len(candidates), 2))
    y = np.log(np.fabs(signal_clean(time, 1)))
    
    for c in range(len(candidates)):
        
        fit[c] = np.polyfit(x=time[candidates[c]],
                            y=y[candidates[c]],
                            deg=1,
                            w=np.repeat(std, len(candidates[c])))
    
    return fit


def get_time_constant(candidate_fit):
    
    """
    The function calculates the time constant of a valid candidate

        :param candidate_fit: np.ndarray 
            array of coefficients m (angular coeff), q (intercept) of the valid candidate

    :return: float
        time constant of the valid candidate 
    """
    
    # check sul coefficiente angolare
    if np.isnan(candidate_fit)[0]:
        return None
    
    return round(-1 / candidate_fit[0], 6)


def get_time_constants(candidates_fit):
    
    """
    The function calculates the time constants for each valid candidate

        :param candidates_fit: list of np.ndarrays 
            matrix of slope coefficients and intercepts of valid candidates of a TES
            (num valid candidates x 2 (m, q) )

    :return: list
        list of valid candidate time constants
    """
    
    return list(map(get_time_constant, candidates_fit))


def tau_filter(tau: float, tau_coeff: float, epsilon: float) -> bool:
    
    """
    The function filters the candidate's time constant based on a given condition

        :param tau: float 
            time constant of the valid candidate

        :param tau_coeff: float
            time constant of the TES with which to compare the time constants of valid candidates of the TES

        :param epsilon: float
           threshold with which I establish whether the time constant of the TES is comparable with that of the 
           valid candidate under examination

    :return: bool
        True if the time constant is valid
        False if the time constant is not valid
    """
    
    return np.fabs(tau - tau_coeff) < epsilon


def taus_filter(taus: list, tau_coeff: float, epsilon: float) -> list:
    
    """
    The function filters the time constants of candidates based on a given condition

        :param taus: list 
            list containing the time constants of valid candidates

        :param tau_coeff: float
            time constant of the TES with which to compare the time constants of valid candidates of the TES

        :param epsilon: float
            threshold with which I establish whether the time constant of the TES is comparable with that of the 
            valid candidate under examination
    
    :return: list
        filtered time constants
    """
    
    return list(filter(lambda tau: tau_filter(tau, tau_coeff, epsilon), taus))


def write_data(taus_fname: str, tes_num: int, taus: list):
    
    if not taus:
        return 
    
    with open(taus_fname.format(tes_num), "w") as fout:
        fout.write(",".join(map(str, taus)))
        
    return tes_num
        
    
def find_cosmic_rays(time_fname: str, signals_fname: str, taus_fname: str, tes_num: int, tau_coeff: float):
    
    """
    Function that searches for cosmic rays above noise
    
        :param time_fname: str
             path to the file where the time values are saved
        
        :param signals_fname: srt
            path to the file where the signal values are saved
            
        :param taus_fname: srt
            path to the file where the time constant values are saved
        
        :param n_tes: int
            TES number

        :param tau_coeff: float
            time constant of the TES with which to compare the time constants of valid candidates of the TES
    
    :return: list
        time constants comparable with the time constant of the TES
    
    """
    
    std_coeff = 5
    points_per_candidate = 7
    epsilon = 1e-2
    
    _, s_clean = interpolated_signal(tes_num=tes_num,
                                     time_fname=time_fname,
                                     signals_fname=signals_fname)
    
    candidates = get_candidates(tes_num=tes_num,
                                    time_fname=time_fname, 
                                    signal_clean=s_clean,
                                    std_coeff=std_coeff, 
                                    points_per_candidate=points_per_candidate) 
    
    print(f"N. Candidates {len(candidates)}")
    
    valid_candidates = candidates_filter(time_fname=time_fname,
                                        signal_clean=s_clean,
                                        candidates=candidates)
    
    print(f"N. Valid Candidates {len(valid_candidates)}")
    
    fit_valid_candidates = get_fit_candidates(time_fname=time_fname,
                                              signal_clean=s_clean,
                                              candidates=valid_candidates)
    
    taus = get_time_constants(fit_valid_candidates)

    filtered_taus = taus_filter(taus, tau_coeff, epsilon)
    
    write_data(taus_fname, tes_num, filtered_taus)

    return filtered_taus
```

```{python}
start = tm.perf_counter()
time_fname, signals_fname, taus_fname = configure_data_dir(data_storage_path=data_storage_path, 
                                                           data_set_path=data_set_path,
                                                           qubic_interpreter=qubic_interpreter)

filtered_taus = find_cosmic_rays(time_fname, signals_fname, taus_fname, 93, 50e-3)
stop = tm.perf_counter()

print(f"N. time constants: {len(filtered_taus)}")
print(f"Elapsed time: {stop - start:.2f}[s]")
```

# Testing individual pieces of code

```{python}
# Loading data

time_raw = np.load(time_fname)
signals = np.load(signals_fname)
```

```{python}
# Parameter setting

tes_num = "93" 
std_coeff = 5
points_per_candidate = 7
points_vertical_trend = 7
time_raw -= time_raw[0]
s_raw = signals[tes_num]

_, s_clean = interpolated_signal(tes_num=tes_num,
                                 time_fname=time_fname,
                                 signals_fname=signals_fname)

s_clean_fabs = np.fabs(s_clean(time_raw, 1))
```

```{python}
#print(tm.ctime(time_raw[0])) # observation start time
#print(tm.ctime(time_raw[-1])) # observation end time
```

```{python}
fig, ax = plt.subplots(figsize=(15,8))
ax.set_title(f"Signal - TES {int(tes_num) + 1}")
ax.set(xlabel="time [s]", ylabel="S [ADU]")

ax.plot(time_raw, s_raw);
```

```{python}
_, ax = plt.subplots(figsize=(15,8))
ax.set_title(f"Signal without atmospheric drifts - TES {int(tes_num) + 1}")
ax.set(xlabel="time [s]", ylabel="S [ADU]")

ax.plot(time_raw, s_clean_fabs, alpha=0.3);
ax.plot(time_raw, np.repeat(std_coeff*np.std(s_clean_fabs), len(time_raw)));
```

```{python}
## Creation of the file containing the plots of ALL candidates for each TES - 
## with attached the trend of "points_vertical_trend" points PRECEDING the candidate

# all candidates (valid and not)
candidates = get_candidates(tes_num, time_fname, s_clean, std_coeff, points_per_candidate) 

col = 3 if len(candidates) >= 3 else 1
row = int(round(len(candidates)/col)) if len(candidates) >= col else 1

if row*col < len(candidates):
    row += 1
    
candidates_figsize = {1: (8,5), 2: (6,8)}
        
fig, ax = plt.subplots(row, col, figsize=candidates_figsize[len(candidates)] if len(candidates) < 3 else (12,20)) 
fig.suptitle(f"N. Candidates {len(candidates)} - TES {tes_num}")


for index in range(len(candidates)):
    x_plot = index // col
    y_plot = index % col
    
    first_vertical_point = max(0, candidates[index][0] - points_vertical_trend)
    time_signal_index = list(range(first_vertical_point, candidates[index][0])) + candidates[index]
        
    if col > 1:
        ax[x_plot][y_plot].scatter(time_raw[time_signal_index], s_clean_fabs[time_signal_index])
        ax[x_plot][y_plot].set_xlabel("Time [s]")
        ax[x_plot][y_plot].set_ylabel("Signal [ADU]")
    else:
        if row > 1:
            ax[x_plot].scatter(time_raw[time_signal_index], s_clean_fabs[time_signal_index])
            ax[x_plot].set_xlabel("Time [s]")
            ax[x_plot].set_ylabel("Signal [ADU]")
        else:
            ax.scatter(time_raw[time_signal_index], s_clean_fabs[time_signal_index])
            ax.set_xlabel("Time [s]")
            ax.set_ylabel("Signal [ADU]")
            

plt.tight_layout()
plt.subplots_adjust(top=0.93)
plt.savefig(f"candidates_plots_TES_{tes_num}")
```

```{python}
## Creation of the file containing the plots of ALL candidates for each TES

# all candidates (valid and not)
candidates = get_candidates(tes_num, time_fname, s_clean, std_coeff, points_per_candidate) 

col = 3 if len(candidates) >= 3 else 1
row = int(round(len(candidates)/col)) if len(candidates) >= col else 1

if row*col < len(candidates):
    row += 1
    
candidates_figsize = {1: (8,5), 2: (6,8)}
        
fig, ax = plt.subplots(row, col, figsize=candidates_figsize[len(candidates)] if len(candidates) < 3 else (12,20)) 
fig.suptitle(f"N. Candidates {len(candidates)} - TES {tes_num}")


for index in range(len(candidates)):
    x_plot = index // col
    y_plot = index % col
        
    if col > 1:
        ax[x_plot][y_plot].scatter(time_raw[candidates[index]], s_clean_fabs[candidates[index]])
        ax[x_plot][y_plot].set_xlabel("Time [s]")
        ax[x_plot][y_plot].set_ylabel("Signal [ADU]")
    else:
        if row > 1:
            ax[x_plot].scatter(time_raw[candidates[index]], s_clean_fabs[candidates[index]])
            ax[x_plot].set_xlabel("Time [s]")
            ax[x_plot].set_ylabel("Signal [ADU]")
        else:
            ax.scatter(time_raw[candidates[index]], s_clean_fabs[candidates[index]])
            ax.set_xlabel("Time [s]")
            ax.set_ylabel("Signal [ADU]")
            

plt.tight_layout()
plt.subplots_adjust(top=0.93)
plt.savefig(f"candidates_plots_TES_{tes_num}")
```

```{python}
## Creation of the file containing the plots of the VALID candidates for each TES

valid_candidates = candidates_filter(time_fname, s_clean, candidates)
fit_valid_candidates = get_fit_candidates(time_fname, s_clean, candidates)

if not len(valid_candidates):
    print("There are no valid candidates")
    
else: 
    
    col = 2
    row = len(valid_candidates)
    
    valid_figsize = {1: (10,4), 2: (6,8)}

    fig, ax = plt.subplots(row, col, 
                           figsize=valid_figsize[len(valid_candidates)] if len(valid_candidates) < 3 else (10, 10)) # 9,6
    fig.suptitle(f"N. Valid Candidates {len(valid_candidates)} - TES {tes_num}")

    if row > 1:
        ax[0][0].set_title("Signal VS Time")
        ax[0][1].set_title("Linear fit")
    else:
        ax[0].set_title("Signal VS Time")
        ax[1].set_title("Linear fit")

    for index in range(0, row):

        y_plot = 0 

        y = lambda t: fit_valid_candidates[index][0]*t + fit_valid_candidates[index][1]

        if row > 1:
            ax[index][y_plot].scatter(time_raw[valid_candidates[index]], s_clean_fabs[valid_candidates[index]])
            ax[index][y_plot].set_xlabel("Time [s]")
            ax[index][y_plot].set_ylabel("Signal [ADU]")


            ax[index][y_plot+1].scatter(time_raw[valid_candidates[index]], 
                                        np.log(s_clean_fabs[valid_candidates[index]]))

            ax[index][y_plot+1].plot(time_raw[valid_candidates[index]], 
                                     y(time_raw[valid_candidates[index]]),
                                     label=f"tau = {-1/fit_valid_candidates[index][0]:.3f} [s]",
                                     color="C1")

            ax[index][y_plot+1].set_xlabel("Time [s]")
            ax[index][y_plot+1].set_ylabel("log(Signal) [ADU]")
            ax[index][y_plot+1].legend()
        
        else:
            ax[y_plot].scatter(time_raw[valid_candidates[index]], s_clean_fabs[valid_candidates[index]])
            ax[y_plot].set_xlabel("Time [s]")
            ax[y_plot].set_ylabel("Signal [ADU]")


            ax[y_plot+1].scatter(time_raw[valid_candidates[index]], 
                                        np.log(s_clean_fabs[valid_candidates[index]]))

            ax[y_plot+1].plot(time_raw[valid_candidates[index]], 
                                     y(time_raw[valid_candidates[index]]),
                                     label=f"tau = {-1/fit_valid_candidates[index][0]:.3f} [s]",
                                     color="C1")

            ax[y_plot+1].set_xlabel("Time [s]")
            ax[y_plot+1].set_ylabel("log(Signal) [ADU]")
            ax[y_plot+1].legend()
            

    plt.tight_layout()
    plt.subplots_adjust(top=0.90)
    plt.savefig(f"valid_candidates_fit_TES_{tes_num}")    
```

```{python}

```
