---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.7.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

#### Author: MartÃ­n Gamboa

Analize the simulations for the study of the Frequency Point Spread Function (PSF). The instrument has angular and frequency resolution. Both are defined by the instrumental features.

The angular resolution can be approximated by the following expression: $FWHM_{\theta} = \frac{c}{\nu~(P-1)~\Delta h}$ \\

The frequency resolution is a bit more complex and in this notebook we study it with simulations. The set of simulations are at NERSC in the common directory within mmgamboa user.

For each simulation: 
* read files (two different formats)
* plot raw data
* fit gaussian 

```{python}
from importlib import reload
import pickle as pk
import os
import sys
import time
import glob

import healpy as hp
import numpy as np
import matplotlib as mp
import pandas as pd 

import scipy.stats as sc
from scipy.optimize import curve_fit
from scipy.interpolate import interp1d
from scipy import interpolate

import matplotlib.pyplot as plt
from matplotlib.pyplot import cm
from matplotlib.patches import Ellipse
from matplotlib.animation import FuncAnimation

from lmfit import Model
from astropy.io import fits

import qubic
from qubicpack.utilities import Qubic_DataDir

import AnalysisPSF as anpsf

# #%matplotlib notebook
```

```{python}
def normalization(x,mapa):
    ef = np.trapz((np.trapz(mapa,x,axis=0)),x)
    return 1/ef

def gaussian2d(z, amp,x0, y0, varx, vary):
    x=z[0]
    y=z[1]
    gauss = amp*np.exp(-0.5*((x-x0)**2/varx**2+(y-y0)**2/vary**2))
    return gauss.ravel()

def get_maps(file):
    simu = fits.open(file)

    maps_recon = simu['MAPS_RECON'].data
    maps_convo = simu['MAPS_CONVOLVED'].data

    diff = maps_recon - maps_convo

    return maps_recon, maps_convo, diff

def get_maps_many_files(rep_simu, name, verbose = True, nfreq = None, nside = 256):
    
    all_fits = glob.glob(rep_simu + name)
    nfiles = len(all_fits)
    if verbose:
        print('{} files have been found.'.format(nfiles))

    all_maps_recon = []
    all_maps_convo = []
    all_maps_diff = []
    
    if nfiles == 0:
        map_recon = np.full((nfreq, 12 * nside ** 2, 3), np.nan)
        map_convo = np.full((nfreq, 12 * nside ** 2, 3), np.nan)
        map_diff = np.full((nfreq, 12 * nside ** 2, 3), np.nan)
        all_maps_recon.append(map_recon)
        all_maps_convo.append(map_convo)
        all_maps_diff.append(map_diff)
        print('\t filling array with nan values.')
        del map_recon, map_convo, map_diff
    else:
        for i, fits in enumerate(all_fits):
            map_recon, map_convo, map_diff = get_maps(fits)
            if i == 0:
                right_shape = map_recon.shape
            else:
                if map_recon.shape != right_shape:
                    raise ValueError('You should take maps with identical shapes.')
            all_maps_recon.append(map_recon)
            all_maps_convo.append(map_convo)
            all_maps_diff.append(map_diff)

    return all_fits, np.asarray(all_maps_recon), \
           np.asarray(all_maps_convo), np.asarray(all_maps_diff)

def read_run(jobid, repo=None, fixpar=True):
    """
    Supose: dictionary inside directory
    
    =====================
    Parameters:
        jobid: number jobid from NERSC
        repo: directory where runs are
        fixpar: some parameters had have change from original dictionary values. These allows adapt it
    Return:
        
    """
    repo = os.environ['QUBIC_DATADIR']+'scripts/Spectroimagery_paper/output_paper/nersc/{}/'.format(jobid)
    repodict = glob.glob(repo+'*.dict')[0]

    d = qubic.qubicdict.qubicDict()
    d.read_from_file(repodict)
    center = qubic.equ2gal(d['RA_center'], d['DEC_center'])
    if fixpar:
        d['nf_sub'] = 48
        d['nf_recon'] = [2,3,4]
    
    _,_,nus_in,_,_,_ = qubic.compute_freq(150,d['nf_sub'],0.25)
    sigma2fwhm = np.sqrt(8*np.log(2))
    # constant angular resolution using P = 19 and deltaX = 1.4cm
    CteConf = d['synthbeam_peak150_fwhm'] * 150 #61.57622 #2.998e10/20/1.4/1e9/np.pi*180
    size = 200
    reso = 3
    nside = d['nside']
    
    print("Working with nf_sub = {} and nfrec = {}".format(d['nf_sub'], d['nf_recon']))
    mapsrec={}
    mapsconv={}
    nusfull = {}
    nusfulledge = {}
    for isub in d['nf_recon']:
        _, maprec, mapconv, mapdif = get_maps_many_files(repo, '*recon{}*.fits'.format(isub),
                                                        nfreq = isub, nside = nside )
        _, inusedge, inus, _, _, _ = qubic.compute_freq(150,isub,0.25)
        mapsrec.update({'{}'.format(isub): maprec})
        mapsconv.update({'{}'.format(isub): mapconv})
        nusfull.update({'{}'.format(isub):inus})    
        nusfulledge.update({'{}'.format(isub):inusedge})    
    
    return mapsrec, mapsconv,nusfull,nusfulledge, nus_in, center,d
```

```{python}
dictshift = {'34245779': -23, '34245774': -21,'34145323':-19,'34145299':-17, 
             '33409471':-15,'33409418':-13, '33130322':-11,'33130175':-9,
             '32832344':-7, '33130311':-5, '32759969':-4,'32759907':-3, 
             '32574156':-2, '32574178':-1,'32574170':0, '32759934': 1,
             '32574174': 2, '32759973':3, '33130307':5, '32832346':7, 
             '33130149':9,'33130316':11,'33409459':13,'33409482':15}

jobids = list(dictshift.keys())

allrecon = []
allconv = []
jobid = np.zeros((len(jobids)))
for ijob in range(len(jobids)):
    print('Reading job {} ({}/{})'.format(jobids[ijob],ijob+1,len(jobids)))
    if ijob == 0:
        maprec, mapsconv, nusfull,nusfulledge,nus_in,center,d = read_run(jobids[ijob])
    else: 
        maprec, mapsconv, _, _, _, _, _ = read_run(jobids[ijob])
        
    allrecon.append(maprec)
    allconv.append(mapsconv)
allrecon = np.array(allrecon)
allconv = np.array(allconv)

#Index where the point source was placed
NU0 = 150

innu0 = min(range(len(nus_in)), key = lambda i: abs(nus_in[i]-NU0))
innu = []
for ishift in dictshift.values():
    innu.append(innu0+ishift)
```

Save data for one pixel. I will create 3 structures: data_2bands, data_3bands, data_4bands. Each one has the amplitude for each realization, each frequency, each Stokes parameter (by the time only 'I' component it matters). You'll find 'nan' values for some simulations, this is due to the TIMEOUT in the end-to-end simulation.

```{python}
pixel = hp.pixelfunc.ang2pix(d['nside'], np.deg2rad(90 - center[1]), np.deg2rad(center[0]))

data_2bands = {'nu_in': nus_in[innu],
              'nu_rec': nusfull['2'],
              'nu_edge': nusfulledge['2']}
data_3bands = {'nu_in': nus_in[innu],
              'nu_rec': nusfull['3'],
               'nu_edge': nusfulledge['3'] }
data_4bands = {'nu_in': nus_in[innu],
                'nu_rec': nusfull['4'],
               'nu_edge': nusfulledge['4'] }
for irec in d['nf_recon']:
    keys = ['band{}'.format(i) for i in range(irec)]
    
    for bnd in range(irec):
        auxarr = np.empty((len(jobids)), dtype = object)
        
        for isim in range(len(jobids)):
            auxarr[isim] = allrecon[isim]['{}'.format(irec)][0, bnd, pixel, 0]
        locals()["data_{}bands".format(irec)].update({keys[bnd] : auxarr}) 

#Normalization
max2bands = np.max([np.max(data_2bands['band{}'.format(i)]) for i in range(2)])
max3bands = np.max([np.max(data_3bands['band{}'.format(i)]) for i in range(3)])
max4bands = np.max([np.max(data_4bands['band{}'.format(i)]) for i in range(4)])

for i in range(2):
    data_2bands['band{}'.format(i)] /= max2bands
for i in range(3):
    data_3bands['band{}'.format(i)] /= max3bands
for i in range(4):
    data_4bands['band{}'.format(i)] /= max4bands
```

*Sub-band profile*. Plot intensity for all simulations for the pixel in a given sub-band in function of thefrequency of the point source $\nu_{in}$. The maximum should correspond when the distance between the center of the sub-band $\nu_{jc}$ and the position (in frequency) of the point source is minimum.

We plot in grey the sub-band considered.

```{python}
for NUS in ['2', '3', '4']:

    NormFact = 1#48/int(NUS)
    
    data_array = locals()['data_{}bands'.format(int(NUS))]
    fig,ax = plt.subplots(nrows = 1, ncols = int(NUS), figsize = (18,4), sharey = True)
    ax = ax.ravel()
    
    for j in range(int(NUS)):
    
        color = iter(cm.jet(np.linspace(0,1,3)))
        
        ax[j].set_title(r'band - {:.0f}-{:.0f}GHz'.format(nusfulledge[NUS][j],
                                                          nusfulledge[NUS][j+1]))
        ax[j].set_xlabel(r'$\nu$[GHz]')

        ax[j].set_ylabel(r'$I_\nu(px)$')
        ax[j].set_xlim(data_array['nu_in'][0] * 0.98, data_array['nu_in'][-1] * 1.02)
        
        xvals = nus_in[innu] - data_array['nu_rec'][j]
        
        ax[j].plot(data_array['nu_in'], data_array['band{}'.format(j)], 'o', c = next(color), ms = 12)
        
        xlim = ax[j].get_xlim()
        for iedge in data_array['nu_edge']:
            if (iedge > np.array(xlim)[0]) and (iedge < np.array(xlim)[1]):
                ax[j].axvline(iedge, color='k', ls='--')
        ax[j].grid()
        ax[j].axvspan(data_array['nu_edge'][j], data_array['nu_edge'][j + 1], 
                      color = 'k', alpha = 0.20)
        ax[j].axvline(data_array['nu_rec'][j], ls = '-.', c = 'k')
        
```

Superimpose each sub-band by substracting $\nu_{jc}$ (no normalized by the width, it's not necessary) 

```{python}
fig, ax = plt.subplots(nrows = 1, ncols = 3, 
                       sharey = True, figsize = (12,6))

iax = 0
for sb in [2,3,4]:
    data_array = locals()['data_{}bands'.format(sb)]
    
    xx, yy = [], []
    #print(sb)
    for j in range(sb):
        xx.append(data_array['nu_in'] - data_array['nu_rec'][j])
        yy.append(data_array['band{}'.format(j)])
    
    #bla = [np.array([0,2,4]),np.array([1,3,5])]
    #ble = [np.array([0.0, 0.2, 0.4]), np.array([0.1,0.3,0.5])]
    xsort_idx = np.argsort(np.array(xx).ravel())
    #print(np.array(ble).ravel()[argsort])
    xx = np.array(xx).ravel()[xsort_idx]
    yy = np.array(yy).ravel()[xsort_idx]
    
    #print(xx, yy)
    data = ax[iax].plot(np.array(xx).T, np.array(yy).T, 'o', c = 'b')
    
    #Save xData to make a fit
    data_array.update({'Data_fit': data[0].get_data()})
    iax += 1
plt.tight_layout()

```

## Another way to plot the same data

See how the FPSF change when it changes the frequency of the point source

```{python}
for ibnd in [2,3,4]:
    fig = plt.figure(figsize=(4, 4))
    ax = fig.gca()
    data_array = locals()['data_{}bands'.format(ibnd)]
    nsimu = len(data_array['nu_in'])
    points, = ax.plot(data_array['nu_rec'], 
                      np.array([data_array['band{}'.format(i)] for i in range(ibnd)]).T[0], 'ko')
    line = ax.axvline(data_array['nu_in'][0], color = 'k', ls = '--')
    text = ax.text(140, 1, r'$\nu_i=${:3.2f} GHz'.format(data_array['nu_in'][0]), fontsize=14)

    def init():
        ax.axhline(0, color = 'k', ls = '-', alpha = 0.2)
        c = ['b', 'g', 'y', 'r']
        for ib in range(ibnd):
            ax.axvspan(xmin = data_array['nu_edge'][ib], xmax = data_array['nu_edge'][ib + 1], 
                       alpha = 0.2, color = c[ib])
        ax.set_xlim(130,170)
        ax.set_xlabel(r'$\nu$ [GHz]')
        ax.set_ylabel(r'$I_{out}$')
        ax.set_ylim(-0.2,1.1)
        return points

    def animate(i):
        points.set_data(data_array['nu_rec'], 
                        np.array([data_array['band{}'.format(i)] for i in range(ibnd)]).T[i])
        line.set_xdata(data_array['nu_in'][i])
        text.set_text(r'$\nu_i=${:3.2f} GHz'.format(data_array['nu_in'][i]))
        return(points)


    steps = np.arange(nsimu)
    anim = FuncAnimation(fig, animate, steps, init_func=init, interval=1000, blit=False, repeat=False)

    # Save a .gif
    anim.save('./{}FPSF.gif'.format(ibnd), writer='imagemagick')
```

## Fit spline 

JCh lines to fit

```{python}
class MySplineFitting:
    def __init__(self, xin, yin, covarin, nbspl, logspace = False):
        # input parameters
        self.x = xin
        self.y = yin
        self.nbspl = nbspl
        covar = covarin
        
        if np.size(np.shape(covarin)) == 1:
            err = covarin
            covar = np.zeros((np.size(err), np.size(err)))
            covar[np.arange(np.size(err)), np.arange(np.size(err))] = err**2
        
        self.covar = covar
        self.invcovar = np.linalg.inv(covar)
        
        # Prepare splines
        xspl = np.linspace(np.min(self.x), np.max(self.x), nbspl)
        if logspace == True: xspl = np.logspace(np.log10(np.min(self.x)), np.log10(np.max(self.x)), nbspl)
        self.xspl = xspl
        F = np.zeros((np.size(xin), nbspl))
        self.F = F
        for i in np.arange(nbspl):
            self.F[:,i] = self.get_spline_tofit(xspl, i, xin)
        
        # solution of the chi square
        ft_cinv_y = np.dot(np.transpose(F), np.dot(self.invcovar, self.y))
        covout = np.linalg.inv(np.dot(np.transpose(F),np.dot(self.invcovar, F)))
        alpha = np.dot(covout, ft_cinv_y)
        fitted = np.dot(F, alpha)
        
        # output
        self.residuals = self.y - fitted
        self.chi2 = np.dot(np.transpose(self.residuals), np.dot(self.invcovar, self.residuals))
        self.ndf = np.size(xin) - np.size(alpha)
        self.alpha = alpha
        self.covout = covout
        self.dalpha = np.sqrt(np.diagonal(covout))
    
    def __call__(self, x):
        theF = np.zeros((np.size(x), self.nbspl))
        for i in np.arange(self.nbspl): theF[:,i] = self.get_spline_tofit(self.xspl, i, x)
        return(np.dot(theF, self.alpha))
    
    def with_alpha(self, x, alpha):
        theF = np.zeros((np.size(x), self.nbspl))
        for i in np.arange(self.nbspl): theF[:,i] = self.get_spline_tofit(self.xspl, i, x)
        return(np.dot(theF, alpha))
            
    def get_spline_tofit(self, xspline, index, xx):
        yspline = np.zeros(np.size(xspline))
        yspline[index] = 1.
        tck = interpolate.splrep(xspline, yspline)
        yy = interpolate.splev(xx, tck, der = 0)
        return(yy)
```

```{python}
# Spline fitting
nbspl = 13
fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize = (12, 4), sharey = True)
jax = 0
for inu in [2, 3, 4]:
    data_dict = locals()["data_{}bands".format(inu)]
    xfit = data_dict['Data_fit'][0]
    yfit = data_dict['Data_fit'][1]
    
    #for nrec = 4 we have NaN's values, so we remove them
    if inu == 4: 
        wnan = np.isnan(data_dict["Data_fit"][1].astype(float))
        xfit = np.delete(xfit, np.where(wnan == True)[0] )
        yfit = np.delete(yfit, np.where(wnan == True)[0] )
        
    myspl = MySplineFitting(xfit, yfit, np.ones(len(xfit)), nbspl)
    
    xvals = np.linspace(np.min(xfit), np.max(xfit), 1000)
    
    ax[jax].plot(xfit, yfit, 'o', color='b', label='Data')
    ax[jax].plot(xvals, myspl(xvals)/np.max(myspl(xvals)), 'r', label='Spline fitting')
    ax[jax].set_xlim(-25,25)
    ax[jax].set_xlabel(r"$\nu - nu_{in}$", fontsize = 14)
    ax[0].set_ylabel(r"$I_{out}$", fontsize = 14)
    
    jax += 1
fig.tight_layout()
```

### Angular resolution


Fit gaussian to profiles.

I will fit the FWHM in the maps where the point source is cleary located in the band. For that I can plot manually and see the SNR level in the edge between band and take those maps where SNR are high and almost constant in the value

```{python}
def gaussian2d_b(x, amp, x0, y0, varx, vary):
    gauss = np.zeros((len(x),len(x)))
    #amp = 1 / (2 * np.pi * varx * vary)
    for i in range(len(x)):
        for j in range(len(x)):
            gauss[i,j] = amp * np.exp(- 0.5 * ( (x[i] - x0) ** 2 / varx ** 2 + \
                                                (x[j] - y0) ** 2 / vary ** 2)  )
            
    return gauss.ravel()

def gaussian2d_1sig(x, amp, x0, y0, var):
    gauss = np.zeros((len(x),len(x)))
    #amp = 1 / (2 * np.pi * varx * vary)
    for i in range(len(x)):
        for j in range(len(x)):
            gauss[i,j] = amp * np.exp(- 0.5 * ( ((x[i] - x0) ** 2 + \
                                                 (x[j] - y0) ** 2) / var ** 2) )
            
    return gauss.ravel()

def normalization(x,mapa):
    '''integral para normalizar la distribucion f(x,y)
    np.trapz(data,x,axis=[])'''    

    ef = np.trapz((np.trapz(mapa,x,axis=0)),x)
    return 1/ef

def f(val, fwhm):
    return np.nan_to_num(np.exp(- 0.5 * val ** 2 / (fwhm / np.sqrt(8 * np.log(2)) ) ** 2))

```

### Calibration

```{python}
nsidecal = 512
NFREQ = 4
reso = 1.5
size = 200

xscale = np.linspace(- size / 2, size / 2, size) * reso / 60

pixel = hp.pixelfunc.ang2pix(nsidecal, np.deg2rad(90 - center[1]), 
                             np.deg2rad(center[0]), nest = False)
vec_pix = hp.pix2vec(nsidecal, pixel)
vec_pixeles = hp.pix2vec(nsidecal, np.arange(12 * nsidecal ** 2))
ang_pixeles = np.arccos(np.dot(vec_pix,vec_pixeles) )
```

```{python}
fwhm = d['synthbeam_peak150_fwhm'] * 150 / nusfull['{}'.format(NFREQ)]

xscalecal = np.copy(xscale)

hpx = True
smooth = True
g0_ud = np.zeros((NFREQ, 12 * nsidecal ** 2,))

for j,fwhm_i in enumerate(fwhm):
    print('Doing {}/{} sample, nu = {:.1f} FWHM = {:.3f} sigma = {:.3f}'.format(j+1,NFREQ, 
                                                            (d['synthbeam_peak150_fwhm'] * 150)/fwhm_i,
                                                            fwhm_i,fwhm_i/np.sqrt(8*np.log(2)) ) )
    if hpx:
        if smooth:
            g0_ud[j, pixel] = 1
            g0_ud[j, :] = 1e5*hp.smoothing(g0_ud[j, :], 
                                        fwhm = np.deg2rad(fwhm[j]),
                                        verbose = False )
        else:
            g0_ud[j,:] = 1e5*f(ang_pixeles, fwhm = np.deg2rad(1.*fwhm_i) )
    else:
        g0_ud[j] = np.reshape(gaussian2d_b(xscalecal, 1e4, 0., 0., 
                                               fwhm_i/np.sqrt(8*np.log(2)), fwhm_i/np.sqrt(8*np.log(2))),
                                   (len(xscalecal), len(xscalecal)))
        
```

#### Reading new simulation of point source

```{python}
#fileloc_0 = 'angularresolution/new-PS_sim_nfsub16-nfrec4-pntg8000_0.fits'
#fileloc_1 = 'angularresolution/new-PS_sim_nfsub16-nfrec4-pntg8000_1.fits'

##tol=1e-4 nrec = 4
#fileloc_2 = 'angularresolution/new-PS_sim_nfsub16-nfrec4-pntg4000_3.fits'

##tol = 1e-5 nrec = 4
#fileloc_3 = 'angularresolution/new-PS_sim_nfsub16-nfrec4-pntg4000-tol1e-05_4.fits'
#fileloc_4 = 'angularresolution/new-PS_sim_nfsub16-nfrec4-pntg4000-tol1e-05_5.fits'

## tol = 1e-5 nrec = 4 nside = 512
fileloc_4 = 'angularresolution/new-PS_sim_nfsub16-nfrec4-pntg4000-tol1e-05_6.fits'
#fileloc_5 = 'angularresolution/new-PS_sim_nfsub16-nfrec4-pntg3000-tol1e-05_8.fits'
#fileloc_5 = 'angularresolution/new-PS_sim_nfsub15-nfrec5-pntg3000-tol1e-05_14.fits'

## tol = 1e-5 nrec = 4 nside = 1024
#fileloc_4 = 'angularresolution/new-PS_sim_nfsub16-nfrec4-pntg3000-tol1e-05_7.fits'

simu_1 = fits.open(fileloc_4)
#simu_2 = fits.open(fileloc_5)

maps_recon_1 = simu_1['MAPS_RECON'].data
maps_convo_1 = simu_1['MAPS_CONVOLVED'].data
#maps_recon_2 = simu_2['MAPS_RECON'].data
#maps_convo_2 = simu_2['MAPS_CONVOLVED'].data
```

```{python}
t1 = time.time()

arrMapsRec = np.array([maps_recon_1,])
fwhmMeasured = np.zeros((len(arrMapsRec),NFREQ)) 
for j_c, maps_recon_i in enumerate(arrMapsRec):
    for j, imap in enumerate(maps_recon_i):
        s0map = hp.gnomview(imap.T[0] / 1e5, rot = center, reso = reso,
                                       return_projected_map = True, xsize = size,
                                       no_plot = True)

        gmodel = Model(gaussian2d_b, independent_vars=['x',], )

        #Set initial guess 
        fwhm_s0init = d['synthbeam_peak150_fwhm'] * 150 / nusfull['{}'.format(NFREQ)][j]

        params = gmodel.make_params(amp = 1, x0 = 0, y0 = 0, 
                                    varx = fwhm_s0init / np.sqrt(8 * np.log(2)), 
                                    vary = fwhm_s0init / np.sqrt(8 * np.log(2)))

        result_s0 = gmodel.fit(s0map.ravel(), params, x = xscale)

        fwhm_s0 = np.sqrt(result_s0.best_values['varx'] * result_s0.best_values['vary']) *\
                                                                                np.sqrt(8 * np.log(2))

        fwhmMeasured[j_c, j] = fwhm_s0
        print('Done {}/{}, fwhm = {}'.format(j + 1, len(arrMapsRec[0]), fwhm_s0))
print('All done in {:.4f} seconds'.format((time.time() - t1) ) )
```

```{python}
delta_fwhm_g = np.zeros((NFREQ))
fwhm_measured_g = []

gmodel_calb_g = Model(gaussian2d_b, independent_vars = ['x',], )

t0 = time.time()

for j,fwhm_i in enumerate(fwhm):
    print('Doing {}/{} sample'.format(j+1,NFREQ))
    sigma_i = fwhm_i / np.sqrt(8 * np.log(2))
    if hpx:
        g0map = hp.gnomview(g0_ud[j,:], rot = center, reso = reso,
                                   return_projected_map = True, xsize = size,
                                   no_plot = True)
    else:
        g0map = g0_ud[j]
    #
    print("Maximum values of the map {:.2e}".format(np.max(g0_ud)))
    print("Initial FWHM = {:.2f}~deg".format(fwhm_i))
    
    g0map *= normalization(xscalecal, g0map)

    gmodel_calb_g.set_param_hint('amp', value = 1e4)#, min = 1e3, max = 1e6)
    gmodel_calb_g.set_param_hint('x0', value = 0)#, min = -0.2, max = 0.2)
    gmodel_calb_g.set_param_hint('y0', value = 0)#, min = -0.2, max = 0.2)
    gmodel_calb_g.set_param_hint('varx', value = sigma_i, )
                               #min = sigma_i*0.2, max = sigma_i*1.8)
    gmodel_calb_g.set_param_hint('vary', value = sigma_i, )
                               #min = sigma_i*0.2, max = sigma_i*1.8)
    
    params_calb_g = gmodel_calb_g.make_params()#amp = 1e5, x0 = 0, y0 = 0, varx = np.radians(0.2), vary = np.radians(0.2))

    result_calb_g = gmodel_calb_g.fit(g0map.ravel(), params = params_calb_g, x = xscalecal )
    
    print('varx {:.2f} vary {:.2f}'.format(result_calb_g.best_values['varx'], 
                                           result_calb_g.best_values['vary']))
    
    fwhm_measured_i = np.sqrt(abs(result_calb_g.best_values['varx'])*abs(result_calb_g.best_values['vary'])) *\
                            np.sqrt(8*np.log(2))
    
    fwhm_measured_g.append(fwhm_measured_i)
    delta_fwhm_g[j] = fwhm_measured_i - fwhm_i
    
    print("Chi2 {:.2f} NU = {:.2f} FWHM {:.2f} th {:.2f}".format(result_calb_g.redchi, 
                                                            nusfull['{}'.format(NFREQ)][j],
                                                            fwhm_measured_i, fwhm_i) )
    
    print('Delta(FWHM) {:.5f}'.format(delta_fwhm_g[j]))

print('Done in {:.2f} min'.format( (time.time() - t0) / 60 ) )

fwhm_measured_g = np.array(fwhm_measured_g)
parsfwhm_g = list(result_calb_g.best_values.values())
```

```{python}
def model_fwhm(x,a,b):
    return a * x + b

xSPSF = d['synthbeam_peak150_fwhm'] * 150 / fwhm
ySPSF_g = delta_fwhm_g

# Model 2 or g
gmodel_fwhm_g = Model(model_fwhm, independent_vars=['x',], )
params_fwhm_g = gmodel_fwhm_g.make_params(a = 1, b = 1)
result_fwhm_g = gmodel_fwhm_g.fit(ySPSF_g, params_fwhm_g, x=xSPSF)
parsfwhm_g = list(result_fwhm_g.best_values.values())
```

```{python}
fig,ax=plt.subplots(nrows = 1, ncols = 1, figsize = (8, 5),
                    sharey = True, gridspec_kw = {'hspace': 0.03})
ax=[ax,]

plt.rc('font', size = 12)

fwhmTh = lambda nu: d['synthbeam_peak150_fwhm'] * 150 / nu

ax[0].set_xlabel(r'$\nu~$[GHz]')
ax[0].set_ylabel(r'$FWHM~$[deg]')

for j in range(4):
    ax[0].plot(nusfull['{}'.format(NFREQ)][j], 
                   fwhmMeasured[0][j] - model_fwhm(nusfull['{}'.format(NFREQ)][j], 
                                                                              *parsfwhm_g) ,
                   color = 'r', marker = '*', ls = "",label = 'FWHM measured' if j == 0 else None)
    ax[0].plot(nusfull['{}'.format(NFREQ)][j], fwhmTh(nusfull['{}'.format(NFREQ)][j]), 'bo', alpha = 0.5, 
               label = 'FWHM theoretical' if j == 0 else None)
    ax[0].legend(fontsize = 14)
ax[0].tick_params(axis = 'both', bottom = True, top = True, 
                  left = True, right = True, direction = 'in')
ax[0].grid()
#
plt.tight_layout() #makes subplots nicely fit in the figure.
#plt.savefig('Angular-Resolution_reso{}_nside{}.pdf'.format(reso, newnside), format = 'pdf')
```

quick computation of time for each simulation. Data taken from iris

```{python}
sisi = np.array([1653,3343,2770,5085,8652])
sisi2=np.array([1604,3507,2723,4976,9036])
sisi3=np.array([1524,3384,2860,4575,8518])
sisi4=np.array([1536,3766,2737,5415,8993])
nsisi= sisi/np.sum(sisi)
nsisi2= sisi2/np.sum(sisi2)
nsisi3= sisi3/np.sum(sisi3)
nsisi4= sisi4/np.sum(sisi4)

t0,t2,t3,t4 = 2571.95*nsisi/60, 2794.24*nsisi2/60, 2495.46*nsisi3/60,2666.2*nsisi4/60
print(t0[1:-1])
print('average recon 2,3,4 sub-freqs {:.2f}hs'.format(np.sum(t0[1:-1])), 2571/60)
print('{:.2f}hs'.format(np.sum(t2[1:-1])), 2794/60)
print('{:.2f}hs'.format(np.sum(t3[1:-1])), 2495/60)
print('{:.2f}hs'.format(np.sum(t4[1:-1])), 2666/60)

```

```{python}

```

```{python}

```

```{python}

```

```{python}

```

Editing xaxis...It should be ~47 values 

### Fit
$\fbox{} \quad \mathrm{Sinusoidal} \quad y_{sin}(x) = \frac{\sin{x}}{x}$ (Model 1)

$\fbox{} \quad \mathrm{Bessel} \quad y_{bes}(x) = 1 - \frac{x^2}{2^2} + \frac{x^4}{2^2~4^2} - \frac{x^6}{2^2~4^2 ~6^2}$ ... (Model 2)

$\fbox{} \quad \mathrm{Polyn} \quad y_{pol}(x) = a+b~x + c~x^2/2+e~x^3/3 +$ ... (Model 3)


Generate models...

```{python}
from scipy.special import j0,j1,jn
#Model 1
def model_sin(x,a,b):#c,e,ph):
    return a*np.sin(b*x)/(b*x)#+ e*np.exp(-c*x-ph)

def model_exp(x, a, b, c, phi, y, y0, y1):
    return a * np.exp(- b * x) * np.cos(c * x + phi) + y + y0 * x + y1 * x ** 2

def model_bes(x,a,b):#,e):
    return a*j0(b*x)#+e*np.exp(-c*(x-x0))

def model_pol(x,a0,a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12):
    return a0+a1*x+a2*x**2+a3*x**3+a4*x**4+a5*x**5+a6*x**6 + \
            a7*x**7+a8*x**8+a9*x**9+a10*x**10+a11*x**11+a12*x**12
```

```{python}
xFPSF = xData
yFPSF = yData

#sinusoidal
gmodel_sin = Model(model_sin, independent_vars=['x',], )
params_sin = gmodel_sin.make_params(a=0.3,b=1)#c=1, e=0.4,ph=0.4)
result_sin = gmodel_sin.fit(yFPSF, params_sin, x=xFPSF)
#result_sin = gmodel_sin.fit(newyData, params_sin, x=newxData)
parssin = list(result_sin.best_values.values())
print('Sin. Chi2 {:.3f}'.format(result_sin.chisqr ))

#exp
gmodel_exp = Model(model_exp, independent_vars=['x',], )
params_exp = gmodel_exp.make_params(a = 1, b = 0.1, c = 0.5,phi = 0., y = 0.5, y0 = 0.1, y1 = 0.5)
result_exp = gmodel_exp.fit(yFPSF, params_exp, x=xFPSF, )
parsexp = list(result_exp.best_values.values())
print('Exp. Chi2 {:.3f}'.format(result_exp.chisqr) )

#bessel
gmodel_bes = Model(model_bes, independent_vars=['x',], )
params_bes = gmodel_bes.make_params(a=0.3,b=0.1,)#c=0.3, e=0.5,x0=0.5 )
result_bes = gmodel_bes.fit(yFPSF, params_bes, x=xFPSF)
#result_bes = gmodel_bes.fit(newyData, params_bes, x=newxData)
parsbes = list(result_bes.best_values.values())
print('Bes. Chi2 {:.3f}'.format(result_bes.chisqr) )

#polynomial
gmodel_pol = Model(model_pol, independent_vars=['x',], )
params_pol = gmodel_pol.make_params(a0=1,a1=1,a2=1,a3=1,a4=1,a5=1,a6=1,a7=1,a8=1,a9=1,a10=1,a11=1,a12=1 )
result_pol = gmodel_pol.fit(yFPSF, params_pol, x=xFPSF)
#result_pol = gmodel_pol.fit(newyData, params_pol, x=newxData)
parspol = list(result_pol.best_values.values())
print('Pol. Chi2 {:.3f}'.format(result_pol.chisqr) )

```

See results...

```{python}
fig = plt.figure(figsize = (10,6))
plt.rc('font', size=16)

result = result_pol
#plt.subplot(121)
plt.plot(xData, result.data, 'bo', label = 'data')
plt.plot(xData, result.best_fit, 'r-', label = 'fit')
dely = result.eval_uncertainty(sigma=3,)
#plt.axvspan(-halfwidth[0],halfwidth[0],color='k',alpha=0.2)
#plt.axvspan(-halfwidth[1],halfwidth[1],color='k',alpha=0.2)
#plt.axvspan(-halfwidth[2],halfwidth[2],color='k',alpha=0.2)
plt.axvspan(-halfwidth[3],halfwidth[3],color='k',alpha=0.2)
#plt.axvspan(-1.5,-0.5,color='k',alpha=0.1)
#plt.axvspan(0.5,1.5,color='k',alpha=0.1)
#plt.xlim(-2.1,2.1)
plt.xlim(-22,22)
plt.fill_between(xData, result.best_fit-dely, result.best_fit+dely, color='red',#"#ABABAB",
                 alpha=0.5, label='3$\sigma$ uncertainty band')
#plt.xlabel(r'${\rm d}_{\nu_c}(\nu)$ ', fontsize = 18)
plt.xlabel(r"$(\nu - \nu_{in})~[\mathrm{GHz}]$", fontsize = 18)
plt.ylabel(r'Normalized FPSF', fontsize = 18)
plt.legend(loc = "best", fontsize = 14)
#plt.subplot(122)
#c = ['b', 'r', 'g', 'm']
#for j, ifr in enumerate(_freqsout_):
#    plt.axvline(x = ifr, ymin = 0.8, ymax = 0.95, linestyle = "--", color = "k")
#    plt.axvline(x = ifr, ymax = 0.65, linestyle = "--", color = "k")
#    plt.text(ifr-2.5, 0.7, "{:.1f}".format(ifr))
#    plt.axvspan(xmin = _freqsEdgeOut_[j], xmax = _freqsEdgeOut_[j + 1], 
#                color = c[j], alpha = 0.2)
#plt.plot((_freqsin_ [:30] ), (fpsf(_freqsin_[:30], _freqsout_[0], _freqswidth_[0]) ), 
#        color = c[0])
#plt.plot((_freqsin_[:38] ), (fpsf(_freqsin_[:38], _freqsout_[1], _freqswidth_[1])),
#        color = c[1])
#plt.plot((_freqsin_[8:] ), (fpsf(_freqsin_[8:], _freqsout_[2], _freqswidth_[2])),
#        color = c[2])
#plt.plot((_freqsin_[12:] ), (fpsf(_freqsin_[12:], _freqsout_[3], _freqswidth_[3])),
#        color = c[3])
plt.tight_layout()
plt.tick_params(axis = 'both', bottom = True, top = True, 
                  left = True, right = True, direction = 'in')
plt.grid()
#savefigs = True
if savefigs:
    plt.savefig('fpsf_nrec{}_new.pdf'.format(np.shape(Data)[0]), format='pdf' , bbox_inches = "tight")
```

```{python}
def model_pol(x,a0,a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12):
    return a0+a1*x+a2*x**2+a3*x**3+a4*x**4+a5*x**5+a6*x**6 + \
            a7*x**7+a8*x**8+a9*x**9+a10*x**10+a11*x**11+a12*x**12

parspol = [1.0148592344536795, 0.09349606938655511, -2.4475688442596186, 
           -0.17550734527944972, 1.8420819896602734, 0.10514202699252193, 
           -0.6316268295742891, -0.02780935772683985, 0.10909049702236638, 
           0.0033055903108466828, -0.009227105490183247, -0.000143491898172274, 
           0.00030356820716515357]

plt.plot(np.linspace(-1.5,1.5)*9.62*2.35+153.65, model_pol(np.linspace(-1.5,1.5),*parspol))
```

```{python}
# TEst FPSF with a fake-map of a point source convolved with quebic resolution
import scipy as sc
# Generate map
ps_map = np.zeros((48, 12 * d['nside'] ** 2, 3))
ps_map_pxcenter = hp.ang2pix(d['nside'], np.radians(90 - center[1]), np.radians(center[0]))
_freqsin_ = qubic.compute_freq(150, 48, 0.25)[2]
_freqsEdgeOut_, _freqsout_, _freqswidth_ = qubic.compute_freq(150, 4, 0.25)[1:4]
_idx_freq_ = 26
print("PS centered in: ", _freqsin_[_idx_freq_])
ps_map[_idx_freq_, ps_map_pxcenter, 0] = 1
ps_map[_idx_freq_, :, 0] = hp.smoothing(ps_map[_idx_freq_, :, 0], verbose = False,
                        fwhm = np.deg2rad(d['synthbeam_peak150_fwhm'] * 150 / _freqsin_[_idx_freq_] ))
#Look at the map..ok
#hp.gnomview(ps_map[_idx_freq_,:,0], rot = center, reso  = 2)

#build the interp function for FPSF
fpsf = lambda nu_i, nu_c, nu_w: np.interp((nu_i - nu_c) / nu_w, xData, result.best_fit)
nbands = 4
#plt.plot((_freqsin_ ), fpsf(_freqsin_, _freqsout_[0], _freqswidth_[0]))
#plt.plot((_freqsin_ ), fpsf(_freqsin_, _freqsout_[1], _freqswidth_[1]))
#plt.plot((_freqsin_ ), fpsf(_freqsin_, _freqsout_[2], _freqswidth_[2]))
#sys.exit()
integr = []
for i in range(nbands):
    integr.append( sc.integrate.simps(ps_map[:, ps_map_pxcenter, 0] * \
          (fpsf(_freqsin_, _freqsout_[i], 2.35*_freqswidth_[i]) )**2*_freqswidth_[i]**2 ,
                                      x = _freqsin_  ) )
    #maskfreq = (_freqsin_ < _freqsEdgeOut_[i+1]) & (_freqsin_ > _freqsEdgeOut_[i])
    #print(maskfreq)
    #integr.append( sc.integrate.simps(ps_map[maskfreq, ps_map_pxcenter, 0] * \
    #      abs(fpsf(_freqsin_[maskfreq], _freqsout_[i], _freqswidth_[i]) ) ,
    #                                  x = _freqsin_[maskfreq]  ) )

#def gauss(x, pars, extra_args = None):
#    A = pars[0]
#    x0 = pars[1]
#    wd = pars[2]
#    return A * np.exp(-0.5 * (x - x0) **2 / wd ** 2)
def gauss(x, A, x0, wd):
    return A * np.exp(-0.5 * (x - x0) **2 / wd ** 2)

test_model = Model(gauss, independent_vars=['x',], )
params_g = test_model.make_params(A = 0.3, x0 = _freqsin_[_idx_freq_], wd = 3)#c=1, e=0.4,ph=0.4)
result_g = test_model.fit(np.array(integr), params_g, x = _freqsout_, weights= (np.diff(_freqsEdgeOut_)/2) )
yvalues = gauss(_freqsin_, **result_g.best_values)
fig, ax = plt.subplots(nrows=1, ncols= 1,)

ax.errorbar(_freqsout_, integr/np.max(yvalues), color = 'r', marker = 'o', 
             ls = " ", xerr = np.diff(_freqsEdgeOut_)/2, )
ax.plot(_freqsin_, yvalues/np.max(yvalues), 'b', 
        label = r'$\sigma$ = {:.2f}'.format(result_g.best_values['wd'] ))
ax.grid(alpha = 0.5)
ax.legend()

#_freqsout_, integr/np.max(yvalues), np.diff(_freqsEdgeOut_)/2)
#(_freqsin_, yvalues/np.max(yvalues))
#print(_freqsin_)
```

```{python}
if np.shape(Data)[0] == 2: xfake=np.linspace(-1.3,1.3)
if np.shape(Data)[0] == 3: xfake=np.linspace(-2.2,2.2)
if np.shape(Data)[0] == 4: xfake=np.linspace(-3,3)
plt.xlabel(r'${\rm d}_{\nu_c}$ / $\Delta \nu$')
plt.ylabel(r'${i_\nu}$[$\mu K$]')
plt.plot(xFPSF, yFPSF, 'bo', label='Data')
plt.plot(xfake,model_sin(xfake, *parssin),'r-',label='Sinusoidal')
plt.plot(xfake,model_exp(xfake, *parsexp),'m-',label='Exponential')
plt.plot(xfake,model_bes(xfake, *parsbes),'g-',label='Bessel')
plt.plot(xfake,model_pol(xfake, *parspol),'c-',label='Polynom')
plt.legend(fontsize=10)
```

```{python}

```

```{python}
def model_fwhm(x,a,b):#,e):
    return a*x+b
xSPSF = d['synthbeam_peak150_fwhm'] * 150 / fwhm#_measured
#ySPSF_f = delta_fwhm_f
ySPSF_g = delta_fwhm_g

# Model 2 or g
gmodel_fwhm_g = Model(model_fwhm, independent_vars=['x',], )
params_fwhm_g = gmodel_fwhm_g.make_params(a=1,b=1)
result_fwhm_g = gmodel_fwhm_g.fit(ySPSF_g, params_fwhm_g, x=xSPSF)
parsfwhm_g = list(result_fwhm_g.best_values.values())
print('Sin. Chi2 {:.3f}'.format(result_fwhm_g.chisqr ))
result_fwhm_g.plot()
```
